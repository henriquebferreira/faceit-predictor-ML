{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; display:flex; justify-content:center; margin:16px 0px\">\n",
    "    <span style=\"color:#ff5500; font-family:Play; font-size:3em; margin:auto 32px\">Part I<br \\>Build Dataset</span>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is a part of the FACEIT Predictor Data Science Workflow.\n",
    "\n",
    "In this notebook the collected data (stored in the local MongoDB database) is preprocessed and new fields/collections are stored directly in the same Database. Therefore, those steps are only executed once and the feature engineering phase is much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:02:16.397924Z",
     "start_time": "2020-03-24T00:02:11.093472Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from pymongo import MongoClient, DESCENDING\n",
    "from pymongo.errors import PyMongoError\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# local modules\n",
    "from config import read_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cfg = read_config(\"local.ingestorDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(**db_cfg)\n",
    "db = client['faceit_imported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the collections inside the ingestor database\n",
    "players_coll = db['player']\n",
    "matches_coll = db['match']\n",
    "lifetime_stats_coll = db['player_lifetime_stats']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Lifetime Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_scoreboard_stats(player_lifetime, player_scoreboard):\n",
    "    for k in player_scoreboard.keys():\n",
    "        player_lifetime[k] -= player_scoreboard.get(k, 0)\n",
    "\n",
    "\n",
    "def get_won_the_match(player_id, match, team_rounds):\n",
    "    player_ids_team_A = [p['id'] for p in match['teamA']]\n",
    "    is_on_team_A = player_id in player_ids_team_A\n",
    "\n",
    "    if (is_on_team_A and team_rounds[0] > team_rounds[1]) or \\\n",
    "            (not is_on_team_A and team_rounds[1] > team_rounds[0]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def update_stats(next_lifetime_stats, player, match):\n",
    "    player_id = player[\"_id\"]\n",
    "    score = match[\"score\"]\n",
    "    map_played = match['mapPlayed']\n",
    "\n",
    "    # create a deep copy of previous map stats\n",
    "    new_lifetime_stats = {k: v for k, v in next_lifetime_stats.items()}\n",
    "    new_lifetime_stats[map_played][\"matches\"] -= 1\n",
    "\n",
    "    team_rounds = [int(r) for r in score.split(\"/\")]\n",
    "    new_lifetime_stats[map_played]['rounds'] -= sum(team_rounds)\n",
    "\n",
    "    won_the_match = get_won_the_match(player_id, match, team_rounds)\n",
    "    new_lifetime_stats[map_played]['wins'] -= won_the_match\n",
    "\n",
    "    players_of_match = [player for team in match['teams']\n",
    "                        for player in team]\n",
    "    player_stats_on_match = [\n",
    "        p for p in players_of_match if p[\"id\"] == player_id][0][\"playerStats\"]\n",
    "\n",
    "    if not player_stats_on_match:\n",
    "        return None\n",
    "        \n",
    "    subtract_scoreboard_stats(\n",
    "        new_lifetime_stats[map_played], player_stats_on_match)\n",
    "\n",
    "    return new_lifetime_stats\n",
    "\n",
    "\n",
    "def get_next_lifetime_stats(player, match_id):\n",
    "    player_id = player[\"_id\"]\n",
    "\n",
    "    # Match history is sorted in temporal descending order\n",
    "    # The following matches are stored in the preceding indexes\n",
    "    next_match_index = -1\n",
    "    for index, m_history in enumerate(player[\"matchHistory\"]):\n",
    "        if m_history[\"id\"] == match_id:\n",
    "            next_match_index = index - 1\n",
    "            break\n",
    "\n",
    "    # If the match was the last to be played (1st one in match history),\n",
    "    # then retrieve the current lifetime stats of the player\n",
    "    if next_match_index < 0:\n",
    "        next_lifetime_stats = player[\"mapStats\"]\n",
    "    else:\n",
    "        previous_match = player[\"matchHistory\"][next_match_index]\n",
    "        next_lifetime_stats = lifetime_stats_coll.find_one(\n",
    "            {\"playerId\": player_id,\n",
    "             \"matchId\": previous_match[\"id\"]},\n",
    "            {\"_id\": 0, \"mapStats\": 1})\n",
    "\n",
    "        if not next_lifetime_stats:\n",
    "            raise PyMongoError(\"No previous lifetime stats\")\n",
    "        \n",
    "        next_lifetime_stats = next_lifetime_stats[\"mapStats\"]\n",
    "\n",
    "    return next_lifetime_stats\n",
    "\n",
    "\n",
    "def compute_new_lifetime_stats(player, match):\n",
    "    player_id = player[\"_id\"]\n",
    "    match_id = match[\"_id\"]\n",
    "    match_start_time = match[\"startTime\"]\n",
    "\n",
    "    # return if match was played after player processing time\n",
    "    matches_of_player = [m[\"id\"] for m in player[\"matchHistory\"]]\n",
    "    if match_start_time > player[\"updatedAtIngestor\"] or match_id not in matches_of_player:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        next_lifetime_stats = get_next_lifetime_stats(player, match_id)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    if match[\"mapPlayed\"] not in next_lifetime_stats:\n",
    "        return None\n",
    "\n",
    "    new_stats = {}\n",
    "    new_stats[\"matchId\"] = match_id\n",
    "    new_stats[\"playerId\"] = player_id\n",
    "    new_stats[\"startTime\"] = match_start_time\n",
    "    map_stats = update_stats(next_lifetime_stats, player, match)\n",
    "    if not map_stats:\n",
    "        return None\n",
    "    new_stats[\"mapStats\"] = map_stats\n",
    "\n",
    "    return new_stats\n",
    "\n",
    "\n",
    "def create_all_lifetime_stats(match):\n",
    "    # Get all ids of the players in the match\n",
    "    players_ids = {player['id'] for team in match['teams'] for player in team}\n",
    "\n",
    "    # Get the ids of the players whose lifetime stats\n",
    "    # were already processed for this match\n",
    "    players_ids_processed = set(lifetime_stats_coll.distinct(\"playerId\", {\n",
    "        \"matchId\": match['_id'],\n",
    "        \"playerId\": {\"$in\": list(players_ids)}}))\n",
    "\n",
    "    players_ids_to_process = players_ids - players_ids_processed\n",
    "    if not players_ids_to_process:\n",
    "        return\n",
    "\n",
    "    players_to_process = players_coll.find(\n",
    "        {\"_id\": {\"$in\": list(players_ids_to_process)}})\n",
    "\n",
    "    lifetime_stats = [compute_new_lifetime_stats(\n",
    "        player, match) for player in players_to_process]\n",
    "\n",
    "    # Filter null values\n",
    "    lifetime_stats = [x for x in lifetime_stats if x]\n",
    "    if lifetime_stats:\n",
    "        lifetime_stats_coll.insert_many(lifetime_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_cursor = matches_coll.find({}).sort(\"startTime\", DESCENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in tqdm(matches_cursor, total=matches_coll.estimated_document_count()):\n",
    "    create_all_lifetime_stats(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Processable Matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which matches have full info available:\n",
    "* `match_history`: the match id is in all of the players' match history, and the previous 10 matches are in DB\n",
    "* `lifetime_stats`: the lifetime stats for all players are present in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_ready = defaultdict(lambda: {\"match_history\":0, \"lifetime_stats\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players = players_coll.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in tqdm(all_players, total=players_coll.estimated_document_count()):\n",
    "    prev_matches = sorted(p[\"matchHistory\"], key=lambda x: x[\"startTime\"])\n",
    "    prev_matches_ids = [m[\"id\"] for m in prev_matches]\n",
    "\n",
    "    matches_ids_in_db = set(matches_coll.distinct(\"_id\", {\"_id\":{\"$in\":prev_matches_ids}}))\n",
    "    missing_decay = 0\n",
    "    for index, m in enumerate(prev_matches):\n",
    "        match_id = m[\"id\"]\n",
    "        if match_id not in matches_ids_in_db:\n",
    "            missing_decay = 10\n",
    "            continue\n",
    "        if missing_decay > 0:\n",
    "            missing_decay -= 1\n",
    "        elif missing_decay == 0 and index > 9:\n",
    "            matches_ready[match_id][\"match_history\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lifetime_stats = lifetime_stats_coll.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in tqdm(all_lifetime_stats, total=lifetime_stats_coll.estimated_document_count()):\n",
    "    matches_ready[l[\"matchId\"]][\"lifetime_stats\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processable_match_ids = [m_id for m_id, rd in matches_ready.items()\n",
    "                if rd[\"match_history\"]==10 and rd[\"lifetime_stats\"]==10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH processing\n",
    "# for each match\n",
    "    # for each player\n",
    "        # get lifetime stats and player stats\n",
    "        # concat lifetime, player and match stats\n",
    "        # store the data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_data_fields = ['activatedAt', 'steamCreatedAt', 'updatedAt', 'csgoId','verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_to_process =  matches_coll.find({\"_id\":{\"$in\":processable_match_ids}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_processed = []\n",
    "players_data = {}\n",
    "batch_size = 3000\n",
    "\n",
    "for index, match in enumerate(tqdm(matches_to_process, total=len(processable_match_ids)):\n",
    "    # Get all ids of the players in the match\n",
    "    players_ids = {player['id'] for team in match['teams'] for player in team}\n",
    "\n",
    "    lifetime_stats = lifetime_stats_coll.find({\n",
    "        \"matchId\": match['_id'],\n",
    "        \"playerId\": {\"$in\": list(players_ids)}})\n",
    "    \n",
    "    lifetime_data = {}\n",
    "    for lt in lifetime_stats:\n",
    "        lifetime_data[lt[\"playerId\"]] = lt\n",
    "\n",
    "    \n",
    "    for team in [\"teamA\", \"teamB\"]:\n",
    "        for player in match[team]:\n",
    "            player_id = player[\"id\"]\n",
    "\n",
    "            # check if player already in data, if not retrieve from DB and store\n",
    "            player_data = players_data.get(player_id, None)\n",
    "            if not player_data:\n",
    "                player_data = players_coll.find_one({\"_id\":player_id})\n",
    "                players_data[player_data[\"_id\"]] = player_data\n",
    "                \n",
    "            for player_field in players_data_fields:\n",
    "                player[player_field] = players_data[player_id].get(player_field, None)\n",
    "\n",
    "            player[\"mapStats\"] = lifetime_data[player_id]\n",
    "\n",
    "            player_match_history = player_data[\"matchHistory\"]\n",
    "            match_history_ids = [m['id'] for m in player_match_history]\n",
    "            match_index = match_history_ids.index(match['_id'])\n",
    "            player[\"previousMatches\"] = match_history_ids[match_index+1:match_index+1+10]\n",
    "    match.pop(\"teams\")\n",
    "    matches_processed.append(match)\n",
    "\n",
    "    if index % batch_size == 0 and index > 0:\n",
    "        with open(f'data/dataset/batch_{index // batch_size}.json', 'w') as fp:\n",
    "            json.dump(matches_processed, fp, default=str)\n",
    "        matches_processed.clear()\n",
    "\n",
    "\n",
    "batch_number = (index // batch_size) + 1\n",
    "with open(f'data/dataset/batch_{batch_number}.json', 'w') as fp:\n",
    "    json.dump(matches_processed, fp, default=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edaed6248b0f32b94d0199fc5dbdbd44040abee12f1bfab10571072dd86c73f9"
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

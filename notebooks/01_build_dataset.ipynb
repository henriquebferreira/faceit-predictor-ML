{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#ff5500; font-family:Play; font-size:3em; margin:auto 32px;align:center\">Part I - Build Dataset</h1>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is a part of the FACEIT Predictor Data Science Workflow.\n",
    "\n",
    "In this notebook the collected data (stored in the local MongoDB database) is processed in order to create a dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-24T00:02:16.397924Z",
     "start_time": "2020-03-24T00:02:11.093472Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pymongo import MongoClient, DESCENDING\n",
    "from pymongo.errors import PyMongoError\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "# enable imports from parent directory\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "# local modules\n",
    "from src.db.config import read_config\n",
    "from src.data.build_dataset import create_all_lifetime_stats\n",
    "from src.utils.dirs import INTERIM_DATA_DIR\n",
    "\n",
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "\n",
    "# autoreload extension\n",
    "if \"autoreload\" not in ipython.extension_manager.loaded:\n",
    "   %load_ext autoreload\n",
    "\n",
    "# autoreload python modules\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cfg = read_config(\"local.ingestorDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(**db_cfg)\n",
    "db = client['faceit_imported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the collections inside the ingestor database\n",
    "players_coll = db['player']\n",
    "matches_coll = db['match']\n",
    "lifetime_stats_coll = db['player_lifetime_stats']\n",
    "\n",
    "db_colls = {\"player\": players_coll, \"match\":matches_coll, \"player_lifetime_stats\":lifetime_stats_coll}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of player documents\", players_coll.estimated_document_count())\n",
    "print(\"Number of matches documents\", matches_coll.estimated_document_count())\n",
    "print(\"Number of lifetime stats documents\", lifetime_stats_coll.estimated_document_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player *Schema*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "| Field Name   |      Type      |  Description |\n",
    "|----------|:-------------:|------|\n",
    "| _id |  str | FACEIT account ID formatted as an UUID|\n",
    "| activatedAt |    str  |   Date of activation of the FACEIT account |\n",
    "| steamCreatedAt| datetime |   Date of creation of the Steam account linked to the FACEIT account |\n",
    "| updatedAt | datetime |    Date of the last FACEIT profile update |\n",
    "| csgoId | str |    Steam64ID of the Steam account linked to the FACEIT account |\n",
    "| verified | bool |    Whether or not it is a verified FACEIT account.<br/>(usually reserved to high profile players including pros and streamers) |\n",
    "| mapStats | dict |    Dictionary where keys are the map names and the values are a dictionary<br/>containing the *Lifetime Stats* of the player on the correspondent map.<br/>The stats for each include the following fields:<ul style=\"margin:8px\"><li>kills</li><li>deaths</li><li>assists</li><li>matches</li><li>wins</li><li>rounds</li><li>headshots</li><li>mvps</li><li>tripleKills</li><li>quadraKills</li><li>pentaKills</li></ul>|\n",
    "| updatedAtIngestor | int |    Unix timestamp of the last time the player was processed in the FACEIT Ingestor service |\n",
    "| matchHistory | list |    List of the player's match history containing both match ID and its start time.<br/>It is ordered from the most recent to the oldest match.|\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_player = players_coll.find_one({})\n",
    "pprint(sample_player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match *Schema*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "| Field Name   |      Type      |  Description |\n",
    "|----------|:-------------:|------|\n",
    "| _id |  str | FACEIT match ID |\n",
    "| entity |    str  |   The kind of match it belongs to: matchmaking, hub or championship (tournament). |\n",
    "| entityName| str |   The name of entity in which the match was played.<br/>Regarding the _matchmaking_ entity there are two queues: Free and Premium.<br/>As for the other cases the entity name is the name of the hub or tournament.|\n",
    "| mapPlayed | str |    The CS GO map where the match was played. |\n",
    "| parties | dict |    Dictionary where the keys are the parties IDs and the values are<br/> the list of the players' IDs in each party. |\n",
    "| score | str |    The score of match: rounds won by team A followed by team B. |\n",
    "| startTime | int |     Unix timestamp of the match start time. |\n",
    "| teamA | list |    List of players in team A. For each player the following fields are collected:<ul style=\"margin:8px\"><li>elo</li><li>id</li><li>membership</li><li>playerStats</li><ul style=\"margin:8px\"><li>kills</li><li>deaths</li><li>assists</li><li>headshots</li><li>mvps</li><li>tripleKills</li><li>quadraKills</li><li>pentaKills</li></ul></ul>|\n",
    "| teamB | list |    Equivalent of teamA but for the players in team B. |\n",
    "| teams | list |    List composed of teamA and teamB fields.|\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_match = matches_coll.find_one({})\n",
    "pprint(sample_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime Stats *Schema*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "| Field Name   |      Type      |  Description |\n",
    "|----------|:-------------:|------|\n",
    "| _id |  str | MongoDB Document ObjectID|\n",
    "| mapStats | dict |    Dictionary where keys are the map names and the values are a dictionary<br/>containing the *Lifetime Stats* of the player on the correspondent map.<br/>The data refers to the lifetime stats right before the start of the match with `_id = matchId`.<br/>The stats for each include the following fields:<ul style=\"margin:8px\"><li>kills</li><li>deaths</li><li>assists</li><li>matches</li><li>wins</li><li>rounds</li><li>headshots</li><li>mvps</li><li>tripleKills</li><li>quadraKills</li><li>pentaKills</li></ul>|\n",
    "| matchId | str |    FACEIT match ID |\n",
    "| playerId | str |   FACEIT account ID formatted as an UUID|\n",
    "| startTime | int |    Unix timestamp of the match start time.|\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lifetime_stats = lifetime_stats_coll.find_one({})\n",
    "pprint(sample_lifetime_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Lifetime Stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially only the most recent lifetime stats are stored in DB (`player.mapStats`). In order to have consistent player lifetime stats for each match and avoid repeating the process over again, the lifetime stats are processed once and stored in DB.\n",
    "\n",
    "To do so one must work backwards and continuously subtract the player stats on each match to the lifetime stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_cursor = matches_coll.find({}).sort(\"startTime\", DESCENDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in tqdm(matches_cursor, total=matches_coll.estimated_document_count()):\n",
    "    create_all_lifetime_stats(m, db_colls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Complete & Processable Matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though there are more than one million matches stored in DB, not all are qualified to be part of the dataset.\n",
    "\n",
    "A valid processable match should have complete player data for every participant. This includes the lifetime stats before the beginning of the match as well as his *10* previous matches.\n",
    "\n",
    "- `match_history`: the match id is in the player's match history and the previous 10 matches are in DB\n",
    "- `lifetime_stats`: the lifetime stats of the player regarding the match are available\n",
    "\n",
    "The `match_history` and `lifetime_stats` are initially set to 0 and incremented each time the conditions are met for one player.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_ready = defaultdict(lambda: {\"match_history\": 0, \"lifetime_stats\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_players = players_coll.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in tqdm(all_players, total=players_coll.estimated_document_count()):\n",
    "    prev_matches = sorted(p[\"matchHistory\"], key=lambda x: x[\"startTime\"])\n",
    "    prev_matches_ids = [m[\"id\"] for m in prev_matches]\n",
    "\n",
    "    matches_ids_in_db = set(matches_coll.distinct(\n",
    "        \"_id\", {\"_id\": {\"$in\": prev_matches_ids}}))\n",
    "    missing_decay = 0\n",
    "    for index, m in enumerate(prev_matches_ids):\n",
    "        match_id = m[\"id\"]\n",
    "        if match_id not in matches_ids_in_db:\n",
    "            missing_decay = 10\n",
    "            continue\n",
    "        \n",
    "        if missing_decay > 0:\n",
    "            missing_decay -= 1\n",
    "        elif missing_decay == 0 and index > 9:\n",
    "            matches_ready[match_id][\"match_history\"] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lifetime_stats = lifetime_stats_coll.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in tqdm(all_lifetime_stats, total=lifetime_stats_coll.estimated_document_count()):\n",
    "    matches_ready[l[\"matchId\"]][\"lifetime_stats\"] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Match Ids\n",
    "Finally, the match ids are filtered to include only those who have full data for all ten players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids = [m_id for m_id, rd in matches_ready.items() if rd[\"match_history\"] == 10 and rd[\"lifetime_stats\"] == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_ids_filename = str(INTERIM_DATA_DIR) + \"\\\\processable_match_ids.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if match_ids:\n",
    "    with open(match_ids_filename, 'wb') as f:\n",
    "        # store the data as binary data stream\n",
    "        pickle.dump(match_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(match_ids_filename, 'rb') as f:\n",
    "    # read the data as binary data stream\n",
    "    match_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of processable matches 68917\n"
     ]
    }
   ],
   "source": [
    "num_matches = len(match_ids)\n",
    "print(\"Number of processable matches\", num_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset stored in batch files of size 2000. The format chosen is CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2000\n",
    "num_batches = (num_matches // batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw data\n",
    "for batch_index in tqdm(range(num_batches), desc=f\"Processing batches of {batch_size}\"):\n",
    "    matches_to_process = list(matches_coll \\\n",
    "        .find({\"_id\": {\"$in\": match_ids}}, {\"teams\":0}) \\\n",
    "        .skip(batch_index*batch_size) \\\n",
    "        .limit(batch_size))\n",
    "\n",
    "    pd.DataFrame(matches_to_process).to_csv(f'../data/raw/batch_{batch_index}.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interim Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate over matches and for each player get the lifetime stats before the beginning of the match as well as the match ids of the 10 previous matches.\n",
    "\n",
    "Store the data of every player on each element of the teamA and teamB lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_data_fields = ['activatedAt', 'steamCreatedAt',\n",
    "                       'updatedAt', 'csgoId', 'verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_to_process = matches_coll.find({\"_id\": {\"$in\": match_ids}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store interim data\n",
    "matches_processed = []\n",
    "players_data = {}\n",
    "\n",
    "\n",
    "for index, match in enumerate(tqdm(matches_to_process, total=len(processable_match_ids))):\n",
    "    # Get all ids of the players in the match\n",
    "    players_ids = {player['id'] for team in match['teams'] for player in team}\n",
    "\n",
    "    lifetime_stats = lifetime_stats_coll.find({\n",
    "        \"matchId\": match['_id'],\n",
    "        \"playerId\": {\"$in\": list(players_ids)}})\n",
    "\n",
    "    lifetime_data = {}\n",
    "    for lt in lifetime_stats:\n",
    "        lifetime_data[lt[\"playerId\"]] = lt\n",
    "\n",
    "    for team in [\"teamA\", \"teamB\"]:\n",
    "        for player in match[team]:\n",
    "            player_id = player[\"id\"]\n",
    "\n",
    "            # check if player already in data, if not retrieve from DB and store\n",
    "            player_data = players_data.get(player_id, None)\n",
    "            if not player_data:\n",
    "                player_data = players_coll.find_one({\"_id\": player_id})\n",
    "                players_data[player_data[\"_id\"]] = player_data\n",
    "\n",
    "            for player_field in players_data_fields:\n",
    "                player[player_field] = players_data[player_id].get(\n",
    "                    player_field, None)\n",
    "\n",
    "            player[\"mapStats\"] = lifetime_data[player_id][\"mapStats\"]\n",
    "\n",
    "            player_match_history = player_data[\"matchHistory\"]\n",
    "            match_history_ids = [m['id'] for m in player_match_history] \n",
    "            match_index = match_history_ids.index(match['_id'])\n",
    "            player[\"previousMatches\"] = match_history_ids[match_index +\n",
    "                                                          1:match_index+1+10]\n",
    "    match.pop(\"teams\")\n",
    "    matches_processed.append(match)\n",
    "\n",
    "    if index % BATCH_SIZE == 0 and index > 0:\n",
    "        pd.DataFrame(matches_processed).to_csv(\n",
    "            f'../data/interim/batch_{(index // BATCH_SIZE)-1}.csv')\n",
    "        matches_processed.clear()\n",
    "\n",
    "\n",
    "batch_number = (index // BATCH_SIZE)\n",
    "pd.DataFrame(matches_processed).csv(\n",
    "    f'../data/interim/batch_{batch_number}.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edaed6248b0f32b94d0199fc5dbdbd44040abee12f1bfab10571072dd86c73f9"
  },
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "383.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

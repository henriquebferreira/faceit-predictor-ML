{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<p>&nbsp;</p>\n",
    "<div style=\"text-align:center\"><span style=\"color:#0CA7DB; font-family:Play; font-size:3em;\">FACEIT Predictor Notebook</span></div>\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "<img style=\"float: center;\" src=\"128.png\">\n",
    "\n",
    "---\n",
    "\n",
    "This notebook covers the development of the Machine Learning model to be used in the browser extension FACEIT Predictor. The model predicts the outcome of Counter Strike Global Offensive (a 5v5 First Person Shooter eSport) matches played on the FACEIT platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Matplotlib-and-Seaborn-defaults\" data-toc-modified-id=\"Matplotlib-and-Seaborn-defaults-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Matplotlib and Seaborn defaults</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Load Data</a></span></li></ul></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Analyze-and-Describe\" data-toc-modified-id=\"Analyze-and-Describe-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Analyze and Describe</a></span></li><li><span><a href=\"#Clean-Data\" data-toc-modified-id=\"Clean-Data-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Clean Data</a></span></li><li><span><a href=\"#Players-Analysis\" data-toc-modified-id=\"Players-Analysis-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Players Analysis</a></span></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#New-Experimental-Features\" data-toc-modified-id=\"New-Experimental-Features-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>New Experimental Features</a></span></li></ul></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Visualization</a></span></li><li><span><a href=\"#Prepare-data-for-training\" data-toc-modified-id=\"Prepare-data-for-training-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Prepare data for training</a></span></li></ul></li><li><span><a href=\"#Baseline\" data-toc-modified-id=\"Baseline-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Baseline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Visualization</a></span></li></ul></li><li><span><a href=\"#Model-and-Feature-Selection\" data-toc-modified-id=\"Model-and-Feature-Selection-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Model and Feature Selection</a></span></li><li><span><a href=\"#Model-Deployment\" data-toc-modified-id=\"Model-Deployment-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Deployment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Save-Model\" data-toc-modified-id=\"Save-Model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Save Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "TODO: WRITE THIS SECTION State the purpose of the notebook here and how it is structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Import libraries and other required jupyter notebooks and python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Options for pandas\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 30\n",
    "\n",
    "# Utils for feature creation\n",
    "from datetime import datetime\n",
    "import math\n",
    "import scipy\n",
    "from statistics import mean\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "# Outlier Detection\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, \n",
    "                              ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier)\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Neural network libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Classifier metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save the ML model\n",
    "import joblib\n",
    "\n",
    "# Display all cell outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from IPython import get_ipython\n",
    "ipython = get_ipython()\n",
    "\n",
    "# Developed python modules\n",
    "import load_faceit_data as loader\n",
    "import add_features\n",
    "# Import other jupyter notebooks\n",
    "#import import_ipynb\n",
    "#import MongoDBAtlas\n",
    "\n",
    "# autoreload extension\n",
    "if 'autoreload' not in ipython.extension_manager.loaded:\n",
    "    %load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "%autosave 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib and Seaborn defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['axes.facecolor'] = 'black'\n",
    "plt.rcParams['figure.facecolor'] = 'none'\n",
    "plt.rcParams['text.color'] = 'white'\n",
    "plt.rcParams['ytick.color'] = 'white'\n",
    "plt.rcParams['xtick.color'] = 'white'\n",
    "plt.rcParams['axes.labelcolor'] = 'white'\n",
    "plt.rcParams['axes.edgecolor'] = 'white'\n",
    "plt.rcParams['axes.labelsize'] = '13'\n",
    "plt.rcParams['axes.titlesize'] = '20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Currently, the data can be loaded in two ways:\n",
    "1. From a locally stored JSON file\n",
    "2. From a MongoDB database hosted in the local network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'filename':'data\\matches_02.json'}\n",
    "dataset = loader.load_data(load_type='json', **params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Describe\n",
    "TODO: Add more functions to pre-analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceit_maps = ['de_train', 'de_inferno', 'de_mirage', 'de_vertigo', 'de_nuke', 'de_overpass', 'de_cache', 'de_dust2']\n",
    "date_format = \"%Y-%m-%dT%H:%M:%SZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(data):\n",
    "    print(\"Dataframe's shape before cleaning\", data.shape)\n",
    "    \n",
    "    data.drop(columns=['_id', '_id__stitch_transaction', 'state', 'match_status'], inplace=True)\n",
    "    data = data[data['score'].notnull()]\n",
    "    data = data[data['mapPlayed'].isin(faceit_maps)]\n",
    "    \n",
    "    # Removal of duplicate matches\n",
    "    data.drop_duplicates(subset=['match_id'],keep=\"first\", inplace=True)\n",
    "    \n",
    "    # Removal of non 5v5 matches\n",
    "    data.loc[:,'num_players'] = data.apply(lambda row: get_num_players(row), axis=1).values\n",
    "    data = data[data['num_players'] == 10]\n",
    "    \n",
    "    print(\"Dataframe's shape after cleaning\", data.shape)\n",
    "    return data\n",
    "\n",
    "def get_num_players(row):\n",
    "    return len(row['teamA']) +len(row['teamB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = clean_dataframe(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Players Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_players_elos(data):\n",
    "    all_players = []\n",
    "    for _, row in data.iterrows():\n",
    "        for player_id,player_info in row['teamA'].items():\n",
    "            all_players.append(player_info['elo'])\n",
    "        for player_id,player_info in row['teamB'].items():\n",
    "            all_players.append(player_info['elo'])\n",
    "    return all_players\n",
    "\n",
    "def get_player_elo_kde(data):\n",
    "    player_elos = get_all_players_elos(data)\n",
    "    player_elos = np.array(player_elos) \n",
    "    player_elos_series = pd.Series(player_elos)\n",
    "    kde = player_elos_series.plot.kde(ind=1000)\n",
    "    xdata, ydata = kde.get_lines()[0].get_data()\n",
    "    return scipy.integrate.cumtrapz(ydata, xdata, dx=1, initial=0), xdata\n",
    "\n",
    "def get_elo_dif_prob(lower_bound, upper_bound, cdf, bins):\n",
    "    lower_bin = (np.abs(bins-lower_bound)).argmin()\n",
    "    upper_bin = (np.abs(bins-upper_bound)).argmin()\n",
    "    return cdf[upper_bin] - cdf[lower_bin]\n",
    "\n",
    "players_elo_distribution, elo_bins = get_player_elo_kde(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_players_info(data):\n",
    "    players_id = []\n",
    "    elos = []\n",
    "    matches = []\n",
    "    winrates = []\n",
    "    kds = []\n",
    "    hs_percents = []\n",
    "    #add createdAt (accounts created a long time ago with few matches might be smurfs)\n",
    "    for _, row in data.iterrows():\n",
    "        for player_id,player_info in row['teamA'].items():\n",
    "            if (player_info['lifetimeData']== None):\n",
    "                players_id.append(0)\n",
    "                elos.append(0)\n",
    "                matches.append(0)\n",
    "                winrates.append(0)\n",
    "                kds.append(0)\n",
    "                hs_percents.append(0)\n",
    "                continue\n",
    "            players_id.append(player_info['id'])\n",
    "            elos.append(player_info['elo'])\n",
    "            matches.append(int(player_info['lifetimeData']['matches']))\n",
    "            winrates.append(int(player_info['lifetimeData']['winRate']))\n",
    "            kds.append(float(player_info['lifetimeData']['averageKD']))\n",
    "            hs_percents.append(int(player_info['lifetimeData']['averageHS']))\n",
    "            \n",
    "        for player_id,player_info in row['teamB'].items():\n",
    "            if (player_info['lifetimeData']== None):\n",
    "                players_id.append(0)\n",
    "                elos.append(0)\n",
    "                matches.append(0)\n",
    "                winrates.append(0)\n",
    "                kds.append(0)\n",
    "                hs_percents.append(0)\n",
    "                continue\n",
    "            players_id.append(player_info['id'])\n",
    "            elos.append(player_info['elo'])\n",
    "            matches.append(int(player_info['lifetimeData']['matches']))\n",
    "            winrates.append(int(player_info['lifetimeData']['winRate']))\n",
    "            kds.append(float(player_info['lifetimeData']['averageKD']))\n",
    "            hs_percents.append(int(player_info['lifetimeData']['averageHS']))\n",
    "            \n",
    "    return np.array(players_id), np.array(elos), np.array(matches), np.array(winrates), np.array(kds), np.array(hs_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_id, elos, matches, winrates, kds, hs_percents = get_all_players_info(dataset)\n",
    "array = [[elos[i], matches[i], winrates[i], kds[i]] for i in range(len(elos))]\n",
    "X = np.array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_winrate = mean(winrates)\n",
    "mean_kd = mean(kds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(contamination=0.05)\n",
    "lof.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smurf_or_cheater_prob(outlier_model):\n",
    "    # Check if user is verified (then, it is probably a pro)\n",
    "    transformed_outlier_factor = []\n",
    "    for i in range(len(outlier_model.negative_outlier_factor_)):\n",
    "        if (outlier_model.negative_outlier_factor_[i]< -1) and (winrates[i]>mean_winrate) and (kds[i]> mean_kd):\n",
    "            transformed_outlier_factor.append(math.log(-outlier_model.negative_outlier_factor_[i])*100)\n",
    "        else:\n",
    "            transformed_outlier_factor.append(0)\n",
    "        arr = np.array(transformed_outlier_factor)     \n",
    "        \n",
    "    team_A = arr.reshape(-1,5)[::2,:]\n",
    "    team_B = arr.reshape(-1,5)[1::2,:]\n",
    "\n",
    "    dataset['smurf_or_cheater_A'] = np.mean(team_A, axis=1)\n",
    "    dataset['smurf_or_cheater_B'] = np.mean(team_B, axis=1)\n",
    "    dataset['dif_smurf_or_cheater'] = dataset['smurf_or_cheater_A'] - dataset['smurf_or_cheater_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smurf_or_cheater_prob(lof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:, 'unix_start_time'] = pd.to_datetime(dataset['startTime'], format=date_format).values.astype('datetime64[s]').astype('int')\n",
    "dataset.drop(columns=['startTime'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_features.add_all_team_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[:, 'missing_info'] = dataset.apply(lambda row: add_features.get_missing_info(row), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dif_elo_prob(row):\n",
    "    return get_elo_dif_prob(row['mean_elo_A'], row['mean_elo_B'], players_elo_distribution, elo_bins)\n",
    "\n",
    "dataset.loc[:,'dif_elo_prob'] = dataset.apply(lambda row: dif_elo_prob(row), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_winner_to_numeric(row):\n",
    "    winner_numeric = 0 if row['score'] == 'faction1' else 1\n",
    "    return winner_numeric\n",
    "\n",
    "dataset.loc[:, 'winner'] = dataset.apply(lambda row: convert_winner_to_numeric(row), axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Experimental Features\n",
    "Creation and test of new features. Once validated the correspondent function should be moved to `add_features.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_winners(dataset):\n",
    "    return dataset[dataset['winner']==0], dataset[dataset['winner']==1]\n",
    "\n",
    "data_winner_A, data_winner_B = split_dataset_winners(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_featured_based_on_winner(feature, num_bins=100, title=None):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    ax = sns.distplot(data_winner_A[feature],\n",
    "                      kde=False,\n",
    "                      bins=num_bins,\n",
    "                      color='#FF5500',\n",
    "                      hist_kws=dict(alpha=0.8))\n",
    "    print('Team A - Feature Mean Value',np.mean(data_winner_A[feature]))\n",
    "    \n",
    "    sns.distplot(data_winner_B[feature],\n",
    "                 kde=False,\n",
    "                 bins=num_bins,\n",
    "                 color='#141616',\n",
    "                 hist_kws=dict(alpha=0.8),\n",
    "                 ax = ax)\n",
    "    print('Team B - Feature Mean Value',np.mean(data_winner_B[feature]))\n",
    "    ax.patch.set_alpha(0.1)\n",
    "    ax.set_title(title)\n",
    "    ax.legend(['A', 'B'], title=\"Winner team\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = comp_featured_based_on_winner('dif_mean_winrate_preference', num_bins=30)\n",
    "\n",
    "# Configure axes limits\n",
    "# ax.set_xlim(x_left, x_right)\n",
    "# ax.set_ylim(y_bottom, y_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['dif_new_players',\n",
    "                'dif_mean_matches',\n",
    "                'dif_mean_matches_on_map',\n",
    "                'dif_mean_winrate_on_map',\n",
    "                'dif_mean_kd_on_map',\n",
    "                'dif_mean_matches_preference',\n",
    "                'dif_mean_winrate_preference',\n",
    "                'dif_mean_kd_preference',\n",
    "                'dif_mean_elo',\n",
    "                'dif_stddev_elo',\n",
    "                'dif_paid_memberships',\n",
    "                'dif_solo_players',\n",
    "                'dif_num_parties',\n",
    "                'dif_mean_matches_on_map_prev',\n",
    "                'dif_mean_winrate_prev',\n",
    "                'dif_multikills_prev',\n",
    "                'dif_mean_assists_prev',\n",
    "                'dif_mean_kd_prev',\n",
    "                'dif_mean_time_prev',\n",
    "                'dif_delta_mean_elo_prev',\n",
    "                'dif_smurf_or_cheater',\n",
    "                'dif_max_time_prev',\n",
    "                'dif_elo_prob',\n",
    "                'dif_first_match',\n",
    "                'dif_mean_time_created_at',\n",
    "                'dif_stddev_time_created_at',\n",
    "                'dif_min_time_created_at',\n",
    "                'dif_mean_matches_today',\n",
    "                'dif_played_map_today',\n",
    "                'dif_have_played_together_prev',\n",
    "                'winner']\n",
    "\n",
    "data_processed = dataset[selected_cols]\n",
    "data_label = dataset['winner']\n",
    "data_features = dataset.drop(columns=['winner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Show graphs and stats here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_features,\n",
    "                                                    data_label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: Random Forest with default parameters\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Baseline Model with slightly better performance\n",
    "    # rf = RandomForestClassifier(n_estimators=1500,\n",
    "    #                             max_features= 0.3,\n",
    "    #                             max_depth=7,\n",
    "    #                             min_samples_leaf=0.005,\n",
    "    #                             random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"Model Score (Mean accuracy on test data)\", model.score(X_test, y_test))\n",
    "    pred = model.predict(X_test)\n",
    "    print(\"\\nClassification Report\")\n",
    "    print(classification_report(y_test, pred))\n",
    "    roc_graph = plot_roc_curve(model, X_test, y_test)\n",
    "    roc_graph.ax_.patch.set_alpha(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the correlation matrix regarding the features present in dataset\n",
    "corr_mat = data_processed.corr()\n",
    "plt.figure(figsize=(20,20))\n",
    "ax = sns.heatmap(corr_mat, annot=True, cbar=False, annot_kws={\"size\": 10})\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_info = permutation_importance(rf, X_train, y_train, n_repeats=10, random_state=0, n_jobs=-1)\n",
    "\n",
    "features_info = list(zip(X_train.columns,\n",
    "                         permutation_info['importances_mean'],\n",
    "                         permutation_info['importances_std']))\n",
    "\n",
    "# Sort by descending mean feature importance\n",
    "features_info = sorted(features_info, key=lambda feature: feature[1], reverse=True)\n",
    "\n",
    "features_imp_df = pd.DataFrame(features_info, columns =['Feature_Name',\n",
    "                                                        'Mean_Importance',\n",
    "                                                        'StdDev_Importance'])\n",
    "\n",
    "features_imp_df.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test set  \n",
    "X_train, X_test, y_train, y_test = train_test_split(data_features,\n",
    "                                                    data_label,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "classifiers = {}\n",
    "classifiers.update({\"LDA\": LinearDiscriminantAnalysis()})\n",
    "classifiers.update({\"QDA\": QuadraticDiscriminantAnalysis()})\n",
    "classifiers.update({\"AdaBoost\": AdaBoostClassifier()})\n",
    "classifiers.update({\"Bagging\": BaggingClassifier()})\n",
    "classifiers.update({\"Extra Trees Ensemble\": ExtraTreesClassifier()})\n",
    "classifiers.update({\"Gradient Boosting\": GradientBoostingClassifier()})\n",
    "classifiers.update({\"Random Forest\": RandomForestClassifier()})\n",
    "classifiers.update({\"Ridge\": RidgeClassifier()})\n",
    "classifiers.update({\"SGD\": SGDClassifier()})\n",
    "classifiers.update({\"BNB\": BernoulliNB()})\n",
    "classifiers.update({\"GNB\": GaussianNB()})\n",
    "classifiers.update({\"KNN\": KNeighborsClassifier()})\n",
    "classifiers.update({\"MLP\": MLPClassifier()})\n",
    "classifiers.update({\"LSVC\": LinearSVC()})\n",
    "classifiers.update({\"NuSVC\": NuSVC()})\n",
    "classifiers.update({\"SVC\": SVC()})\n",
    "classifiers.update({\"DTC\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ETC\": ExtraTreeClassifier()})\n",
    "\n",
    "# Create dict of decision function labels\n",
    "DECISION_FUNCTIONS = {\"Ridge\", \"SGD\", \"LSVC\", \"NuSVC\", \"SVC\"}\n",
    "\n",
    "# Create dict for classifiers with feature_importances_ attribute\n",
    "FEATURE_IMPORTANCE = {\"Gradient Boosting\", \"Extra Trees Ensemble\", \"Random Forest\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter configuration\n",
    "\n",
    "# Initiate parameter grid\n",
    "parameters = {}\n",
    "\n",
    "# Update dict with LDA\n",
    "parameters.update({\"LDA\": {\"classifier__solver\": [\"svd\"], \n",
    "                                         }})\n",
    "\n",
    "# Update dict with QDA\n",
    "parameters.update({\"QDA\": {\"classifier__reg_param\":[0.01*ii for ii in range(0, 101)], \n",
    "                                         }})\n",
    "# Update dict with AdaBoost\n",
    "parameters.update({\"AdaBoost\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__learning_rate\": [0.001, 0.01, 0.05, 0.1, 0.25, 0.50, 0.75, 1.0]\n",
    "                                 }})\n",
    "\n",
    "# Update dict with Bagging\n",
    "parameters.update({\"Bagging\": { \n",
    "                                \"classifier__base_estimator\": [DecisionTreeClassifier(max_depth = ii) for ii in range(1,6)],\n",
    "                                \"classifier__n_estimators\": [200],\n",
    "                                \"classifier__max_features\": [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                                \"classifier__n_jobs\": [-1]\n",
    "                                }})\n",
    "\n",
    "# Update dict with Gradient Boosting\n",
    "parameters.update({\"Gradient Boosting\": { \n",
    "                                        \"classifier__learning_rate\":[0.15,0.1,0.05,0.01,0.005,0.001], \n",
    "                                        \"classifier__n_estimators\": [200],\n",
    "                                        \"classifier__max_depth\": [2,3,4,5,6],\n",
    "                                        \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                        \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                        \"classifier__subsample\": [0.8, 0.9, 1]\n",
    "                                         }})\n",
    "\n",
    "\n",
    "# Update dict with Extra Trees\n",
    "parameters.update({\"Extra Trees Ensemble\": { \n",
    "                                            \"classifier__n_estimators\": [200],\n",
    "                                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                                            \"classifier__max_depth\" : [3, 4, 5, 6, 7, 8],\n",
    "                                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                                            \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                            \"classifier__n_jobs\": [-1]\n",
    "                                             }})\n",
    "\n",
    "\n",
    "# Update dict with Random Forest Parameters\n",
    "parameters.update({\"Random Forest\": { \n",
    "                                    \"classifier__n_estimators\": [400],\n",
    "                                    \"classifier__class_weight\": [\"balanced\"],\n",
    "                                    \"classifier__max_features\": [\"auto\", \"sqrt\"],\n",
    "                                    \"classifier__max_depth\" : [10,11,12],\n",
    "                                    \"classifier__min_samples_split\": [0.001],\n",
    "                                    \"classifier__min_samples_leaf\": [0.001],\n",
    "                                    \"classifier__criterion\" :[\"gini\", \"entropy\"]     ,\n",
    "                                    \"classifier__n_jobs\": [-1]\n",
    "                                     }})\n",
    "\n",
    "\n",
    "# Update dict with Ridge\n",
    "parameters.update({\"Ridge\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with SGD Classifier\n",
    "parameters.update({\"SGD\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0],\n",
    "                            \"classifier__penalty\": [\"l1\", \"l2\"],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with BernoulliNB Classifier\n",
    "parameters.update({\"BNB\": { \n",
    "                            \"classifier__alpha\": [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.25, 0.50, 0.75, 1.0]\n",
    "                             }})\n",
    "\n",
    "# Update dict with GaussianNB Classifier\n",
    "parameters.update({\"GNB\": { \n",
    "                            \"classifier__var_smoothing\": [1e-9, 1e-8,1e-7, 1e-6, 1e-5]\n",
    "                             }})\n",
    "\n",
    "# Update dict with K Nearest Neighbors Classifier\n",
    "parameters.update({\"KNN\": { \n",
    "                            \"classifier__n_neighbors\": list(range(1,31)),\n",
    "                            \"classifier__p\": [1, 2, 3, 4, 5],\n",
    "                            \"classifier__leaf_size\": [5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "                            \"classifier__n_jobs\": [-1]\n",
    "                             }})\n",
    "\n",
    "# Update dict with MLPClassifier\n",
    "parameters.update({\"MLP\": { \n",
    "                            \"classifier__hidden_layer_sizes\": [(5), (10), (5,5), (10,10), (5,5,5), (10,10,10)],\n",
    "                            \"classifier__activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                            \"classifier__learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "                            \"classifier__max_iter\": [100, 200, 300, 500, 1000, 2000],\n",
    "                            \"classifier__alpha\": list(10.0 ** -np.arange(1, 10)),\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"LSVC\": { \n",
    "                            \"classifier__penalty\": [\"l2\"],\n",
    "                            \"classifier__C\": [0.0001, 0.001, 0.01, 0.1, 1.0, 10, 100]\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"NuSVC\": { \n",
    "                            \"classifier__nu\": [0.25, 0.50, 0.75],\n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__degree\": [1,2,3,4,5,6],\n",
    "                             }})\n",
    "\n",
    "parameters.update({\"SVC\": { \n",
    "                            \"classifier__kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "                            \"classifier__gamma\": [\"auto\"],\n",
    "                            \"classifier__C\": [0.1, 0.5, 1, 5, 10, 50, 100],\n",
    "                            \"classifier__degree\": [1, 2, 3, 4, 5, 6]\n",
    "                             }})\n",
    "\n",
    "\n",
    "# Update dict with Decision Tree Classifier\n",
    "parameters.update({\"DTC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})\n",
    "\n",
    "# Update dict with Extra Tree Classifier\n",
    "parameters.update({\"ETC\": { \n",
    "                            \"classifier__criterion\" :[\"gini\", \"entropy\"],\n",
    "                            \"classifier__splitter\": [\"best\", \"random\"],\n",
    "                            \"classifier__class_weight\": [None, \"balanced\"],\n",
    "                            \"classifier__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "                            \"classifier__max_depth\" : [1,2,3, 4, 5, 6, 7, 8],\n",
    "                            \"classifier__min_samples_split\": [0.005, 0.01, 0.05, 0.10],\n",
    "                            \"classifier__min_samples_leaf\": [0.005, 0.01, 0.05, 0.10],\n",
    "                             }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier to use as the base of the recursive feature elimination algorithm\n",
    "selected_classifier = \"Random Forest\"\n",
    "classifier = classifiers[selected_classifier]\n",
    "\n",
    "# Tune classifier (Took = 4.8 minutes)\n",
    "    \n",
    "# Scale features via Z-score normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define steps in pipeline\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline = Pipeline(steps = steps)\n",
    "  \n",
    "# Define parameter grid\n",
    "param_grid = parameters[selected_classifier]\n",
    "\n",
    "# Initialize GridSearch object\n",
    "gscv = GridSearchCV(pipeline, param_grid, cv = 5,  n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n",
    "                  \n",
    "# Fit gscv\n",
    "print(f\"Now tuning {selected_classifier}. Go grab a beer or something.\")\n",
    "gscv.fit(X_train, np.ravel(y_train))  \n",
    "\n",
    "# Get best parameters and score\n",
    "best_params = gscv.best_params_\n",
    "best_score = gscv.best_score_\n",
    "        \n",
    "# Update classifier parameters\n",
    "tuned_params = {item[12:]: best_params[item] for item in best_params}\n",
    "classifier.set_params(**tuned_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features using RFECV\n",
    "class PipelineRFE(Pipeline):\n",
    "    # Source: https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        super(PipelineRFE, self).fit(X, y, **fit_params)\n",
    "        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline for RFECV\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "pipe = PipelineRFE(steps = steps)\n",
    "\n",
    "# Initialize RFECV object\n",
    "feature_selector = RFECV(pipe, cv = 5, step = 1, scoring = \"roc_auc\", verbose = 1)\n",
    "\n",
    "# Fit RFECV\n",
    "feature_selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get selected features\n",
    "feature_names = X_train.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Performance Data\n",
    "performance_curve = {\"Number of Features\": list(range(1, len(feature_names) + 1)),\n",
    "                    \"AUC\": feature_selector.grid_scores_}\n",
    "performance_curve = pd.DataFrame(performance_curve)\n",
    "\n",
    "# Performance vs Number of Features\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "colors = sns.color_palette(\"RdYlGn\", 20)\n",
    "line_color = colors[3]\n",
    "marker_colors = colors[-1]\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots(figsize=(13, 6.5))\n",
    "sns.lineplot(x = \"Number of Features\", y = \"AUC\", data = performance_curve,\n",
    "             color = line_color, lw = 4, ax = ax)\n",
    "sns.regplot(x = performance_curve[\"Number of Features\"], y = performance_curve[\"AUC\"],\n",
    "            color = marker_colors, fit_reg = False, scatter_kws = {\"s\": 200}, ax = ax)\n",
    "\n",
    "# Axes limits\n",
    "plt.xlim(0.5, len(feature_names)+0.5)\n",
    "plt.ylim(0.60, 0.925)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axhline(y = 0.625, color = 'black', linewidth = 1.3, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_curve.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline for RFECV\n",
    "steps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n",
    "pipe = PipelineRFE(steps = steps)\n",
    "\n",
    "# Initialize RFE object\n",
    "feature_selector = RFE(pipe, n_features_to_select =21, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get selected features labels\n",
    "feature_names = X_train.columns\n",
    "selected_features = feature_names[feature_selector.support_].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get selected features data set\n",
    "X_train = X_train[selected_features]\n",
    "X_test = X_test[selected_features]\n",
    "\n",
    "# Train classifier\n",
    "classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_features, columns = [\"Feature Label\"])\n",
    "feature_importance[\"Feature Importance\"] = classifier.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Feature Importance\", ascending=False)\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 1.75)\n",
    "sns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n",
    "               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n",
    "               'ytick.color': '0.4'})\n",
    "\n",
    "# Set figure size and create barplot\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.barplot(x = \"Feature Importance\", y = \"Feature Label\",\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 15)),  data = feature_importance)\n",
    "\n",
    "# Generate a bolded horizontal line at y = 0\n",
    "ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: model version control and auto-deployment\n",
    "\n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(model, 'model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
